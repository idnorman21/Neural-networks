{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Классификация цветов (свёрточная нейросеть) Д/з Игорь Пархоменко",
      "provenance": [],
      "collapsed_sections": [
        "eRteSKZ5VKai"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJHy7vziiPnC"
      },
      "source": [
        "#  Классификация цветов\n",
        "\n",
        "###  Работаем с [Датасетом](https://www.kaggle.com/alxmamaev/flowers-recognition ) для классификации цветов (тюльпан, ромашка, подсолнух, роза, одуванчик).\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fWtymMcR_zZ",
        "outputId": "00d8bef5-eb88-45bb-b6ca-623cfc7a42c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRteSKZ5VKai"
      },
      "source": [
        "# Подготовка датасета и функции для обучения"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXtAgtr2V3u6"
      },
      "source": [
        "Загружаем библиотеки. Фиксируем random.seed для воспроизводимости"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvM84NDjxCnK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3704f1f2-0580-4c76-cd94-f8588c2ffe9b"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision.datasets.utils import download_url\n",
        "from torch.utils.data import random_split\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "random.seed(0)\n",
        "torch.manual_seed(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f3c6d909bb0>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjYDp6nXWWmQ"
      },
      "source": [
        "Выбираем, на чём будем делать вычисления - CPU или GPU (cuda)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzyQGtNfzMsI",
        "outputId": "1721acc9-522f-4c36-bfab-d9951b933fcb"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aV-txOlLyJhK"
      },
      "source": [
        "prepare_imgs = torchvision.transforms.Compose(\n",
        "    [\n",
        "        torchvision.transforms.Resize((224, 224)), #приводим картинки к одному размеру\n",
        "        torchvision.transforms.ToTensor(), # упаковывем их в тензор\n",
        "        torchvision.transforms.Normalize(\n",
        "            mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225] # нормализуем картинки по каналам\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "# задаем датасет. Лейблы - имена папок: \n",
        "dataset = ImageFolder('drive/MyDrive/flowers', transform=prepare_imgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcuefCcB8iwi",
        "outputId": "c7a6e983-1f1f-427a-8013-046ca3cafff5"
      },
      "source": [
        "dataset.imgs[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('drive/MyDrive/flowers/daisy/10172379554_b296050f82_n.jpg', 0)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_DuonGn5HVb"
      },
      "source": [
        "class ValueMeter(object):\n",
        "  \"\"\"\n",
        "  Вспомогательный класс, чтобы отслеживать loss и метрику\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "      self.sum = 0\n",
        "      self.total = 0\n",
        "\n",
        "  def add(self, value, n):\n",
        "      self.sum += value*n\n",
        "      self.total += n\n",
        "\n",
        "  def value(self):\n",
        "      return self.sum/self.total\n",
        "\n",
        "def log(mode, epoch, loss_meter, accuracy_meter, best_perf=None):\n",
        "  \"\"\"\n",
        "  Вспомогательная функция, чтобы \n",
        "  \"\"\"\n",
        "  print(\n",
        "      f\"[{mode}] Epoch: {epoch:0.2f}. \"\n",
        "      f\"Loss: {loss_meter.value():.2f}. \"\n",
        "      f\"Accuracy: {100*accuracy_meter.value():.2f}% \", end=\"\\n\")\n",
        "\n",
        "  if best_perf:\n",
        "      print(f\"[best: {best_perf:0.2f}]%\", end=\"\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JP0M3cL8ZDd3"
      },
      "source": [
        "### Задаём параметры и функцию для обучения. Разбиваем датасет на train/validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwhX2vdquink"
      },
      "source": [
        "batch_size = 32 # размер батча\n",
        "lr = 0.001 # learning rate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IG0zjMWDYu32"
      },
      "source": [
        "Разбиваем датасет на train и validation\n",
        "\n",
        "Задаем dataloader'ы - объекты для итеративной загрузки данных и лейблов для обучения и валидации."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2AW1YTupITs",
        "outputId": "c1c36bb3-92b3-436f-987e-877cfa4a00dd"
      },
      "source": [
        "train_set, val_set = torch.utils.data.random_split(dataset, [len(dataset)-1000, 1000])\n",
        "print('Размер обучающего и валидационного датасета: ', len(train_set), len(val_set))\n",
        "loaders = {'training': DataLoader(train_set, batch_size, pin_memory=True,num_workers=2, shuffle=True),\n",
        "           'validation':DataLoader(val_set, batch_size, pin_memory=True,num_workers=2, shuffle=False)}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размер обучающего и валидационного датасета:  3317 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuiJKWrYZZgb"
      },
      "source": [
        "Функция для подсчета Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xm15u4TsDcIY"
      },
      "source": [
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzW60Io-riGV"
      },
      "source": [
        "Функция для обучения и валидации модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdlXyjEGhU4W"
      },
      "source": [
        "def trainval(model, loaders, optimizer, epochs=10):\n",
        "    \"\"\"\n",
        "    model: модель, которую собираемся обучать\n",
        "    loaders: dict с dataloader'ами для обучения и валидации\n",
        "    optimizer: оптимизатор\n",
        "    epochs: число обучающих эпох (сколько раз пройдемся по всему датасету)\n",
        "    \"\"\"\n",
        "    loss_meter = {'training': ValueMeter(), 'validation': ValueMeter()}\n",
        "    accuracy_meter = {'training': ValueMeter(), 'validation': ValueMeter()}\n",
        "\n",
        "    loss_track = {'training': [], 'validation': []}\n",
        "    accuracy_track = {'training': [], 'validation': []}\n",
        "\n",
        "    for epoch in range(epochs): # итерации по эпохам\n",
        "        for mode in ['training', 'validation']: # обучение - валидация\n",
        "            # считаем градиаент только при обучении:\n",
        "            with torch.set_grad_enabled(mode == 'training'):\n",
        "                # в зависимоти от фазы переводим модель в нужный режим:\n",
        "                model.train() if mode == 'training' else model.eval()\n",
        "                for imgs, labels in tqdm(loaders[mode]):\n",
        "                    imgs = imgs.to(device) # отправляем тензор на GPU\n",
        "                    labels = labels.to(device) \n",
        "                    bs = labels.shape[0]  # размер батча (отличается для последнего батча в лоадере)\n",
        "\n",
        "                    preds = model(imgs) # forward pass - прогоняем тензор с картинками через модель\n",
        "                    loss = F.cross_entropy(preds, labels) # считаем функцию потерь\n",
        "                    acc = accuracy(preds, labels) # считаем метрику\n",
        "\n",
        "                    # храним loss и accuracy для батча\n",
        "                    loss_meter[mode].add(loss.item(), bs)\n",
        "                    accuracy_meter[mode].add(acc, bs)\n",
        "\n",
        "                    # если мы в фазе обучения\n",
        "                    if mode == 'training':\n",
        "                        optimizer.zero_grad() # обнуляем прошлый градиент\n",
        "                        loss.backward() # делаем backward pass (считаем градиент)\n",
        "                        optimizer.step() # обновляем веса\n",
        "            # в конце фазы выводим значения loss и accuracy\n",
        "            log(mode, epoch, loss_meter[mode], accuracy_meter[mode])\n",
        "\n",
        "            # сохраняем результаты по всем эпохам\n",
        "            loss_track[mode].append(loss_meter[mode].value())\n",
        "            accuracy_track[mode].append(accuracy_meter[mode].value())\n",
        "    return loss_track, accuracy_track             "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJFCbGkObf_4"
      },
      "source": [
        "def set_parameter_requires_grad(model):\n",
        "  \"\"\"\n",
        "  Функция для заморозки весов модели\n",
        "  \"\"\"\n",
        "  for param in model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27qiLUtR011m"
      },
      "source": [
        "Попробуем обучить на этих данных свёрточную архитектуру mobilenet_v2.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZGKQ77DqT31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2593b63a-4330-403c-8d95-f501014b39d7"
      },
      "source": [
        "\n",
        "# Не забываем указать, что она модель должна быть предобучена!\n",
        "model = torchvision.models.mobilenet_v2(pretrained=True)\n",
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MobileNetV2(\n",
              "  (features): Sequential(\n",
              "    (0): ConvNormActivation(\n",
              "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU6(inplace=True)\n",
              "    )\n",
              "    (1): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvNormActivation(\n",
              "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (2): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvNormActivation(\n",
              "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvNormActivation(\n",
              "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
              "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (3): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvNormActivation(\n",
              "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvNormActivation(\n",
              "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (4): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvNormActivation(\n",
              "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvNormActivation(\n",
              "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (5): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvNormActivation(\n",
              "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvNormActivation(\n",
              "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (6): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvNormActivation(\n",
              "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvNormActivation(\n",
              "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (7): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvNormActivation(\n",
              "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvNormActivation(\n",
              "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (8): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvNormActivation(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvNormActivation(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (9): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvNormActivation(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvNormActivation(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (10): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvNormActivation(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvNormActivation(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (11): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvNormActivation(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvNormActivation(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (12): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvNormActivation(\n",
              "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvNormActivation(\n",
              "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (13): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvNormActivation(\n",
              "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvNormActivation(\n",
              "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (14): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvNormActivation(\n",
              "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvNormActivation(\n",
              "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (15): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvNormActivation(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvNormActivation(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (16): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvNormActivation(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvNormActivation(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (17): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvNormActivation(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvNormActivation(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (18): ConvNormActivation(\n",
              "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU6(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.2, inplace=False)\n",
              "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "B_yGcrRslDM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zVgqf7x4aOo"
      },
      "source": [
        "set_parameter_requires_grad(model) # передаём модель в функцию для \"заморозки\" градиента"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.classifier = nn.Linear(1280,5)"
      ],
      "metadata": {
        "id": "KbL6MHkblE39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaquxdRWJ_LK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2b56e6f-9050-40fd-98e3-5d6825a790f8"
      },
      "source": [
        "# Проверим, всё ли сработало правильно; выведем веса, которые будут обучаться\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classifier.weight\n",
            "classifier.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTE0EUG9lh5g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "152184f0-046d-4324-ae44-919b0b3549e8"
      },
      "source": [
        "model.to(device) # Отправляем модель на GPU\n",
        "optimizer = torch.optim.Adam(params = model.parameters()) # алгоритм оптимизации\n",
        "loss_track, accuracy_track = trainval(model, loaders, optimizer, epochs=5) # запускаем обучение, задаём количество эпох"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 104/104 [06:27<00:00,  3.73s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[training] Epoch: 0.00. Loss: 0.68. Accuracy: 78.63% \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [01:56<00:00,  3.63s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[validation] Epoch: 0.00. Loss: 0.40. Accuracy: 87.60% \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 104/104 [00:21<00:00,  4.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[training] Epoch: 1.00. Loss: 0.52. Accuracy: 83.28% \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:06<00:00,  4.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[validation] Epoch: 1.00. Loss: 0.37. Accuracy: 88.45% \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 104/104 [00:21<00:00,  4.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[training] Epoch: 2.00. Loss: 0.46. Accuracy: 85.30% \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:06<00:00,  4.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[validation] Epoch: 2.00. Loss: 0.35. Accuracy: 88.57% \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 104/104 [00:21<00:00,  4.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[training] Epoch: 3.00. Loss: 0.42. Accuracy: 86.43% \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:06<00:00,  4.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[validation] Epoch: 3.00. Loss: 0.34. Accuracy: 88.82% \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 104/104 [00:21<00:00,  4.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[training] Epoch: 4.00. Loss: 0.39. Accuracy: 87.27% \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:06<00:00,  4.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[validation] Epoch: 4.00. Loss: 0.34. Accuracy: 88.90% \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}